{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler/anaconda2/envs/fastai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from model import pipeline\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import model.pandas as mpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantileEncoder(cols, target, qs, qnames = None):\n",
    "    if qnames is None:\n",
    "        qnames = [f\"{'_'.join(cols)}_encode_{q * 100}%\" for q in qs]\n",
    "    \n",
    "    def quantileFun(df):\n",
    "        return df.groupby(cols)[target]\\\n",
    "                .quantile(qs)\\\n",
    "                .unstack()\\\n",
    "                .rename({q : qname for q, qname in zip(qs, qnames)}, axis = 1)\n",
    "                \n",
    "    return mpd.joinFun(quantileFun, on = cols, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateDecoder(date_col):\n",
    "    d1 = mpd.columnMapper(lambda x: x.dt.dayofweek, date_col, 'dow')\n",
    "    d2 = mpd.columnMapper(lambda x: x.dt.month, date_col, 'month')\n",
    "    \n",
    "    return pipeline([d1, d2])\n",
    "\n",
    "def timeDecoder(time_col):\n",
    "    t1 = mpd.columnMapper(lambda x: x.str.extract('([0-9]+):[0-9]+', expand = False).astype('int'),\n",
    "                     time_col, 'hour')\n",
    "    t2 = mpd.columnMapper(lambda x: x.str.extract('[0-9]+:([0-9]+)', expand = False).astype('int'),\n",
    "                     time_col, 'minute')\n",
    "    \n",
    "    return t1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E(mpd.Estimator):\n",
    "    def __init__(self, fit_trans):\n",
    "        self.fit_trans = fit_trans\n",
    "    \n",
    "    def fit(self, df):\n",
    "        t, _ = self.fit_trans\n",
    "        return t\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        return self.fit_trans(df)\n",
    "\n",
    "def regularizedQuanitleEncoding(cols, target, qs, qnames = None, splits = 5):\n",
    "    if qnames is None:\n",
    "        qnames = [f\"{'_'.join(cols)}_encode_{q * 100}%\" for q in qs]\n",
    "        \n",
    "    def fit_qenc(train):\n",
    "        folder = KFold(n_splits=splits)\n",
    "        train_enc = []\n",
    "        \n",
    "        for cv_train_ids, cv_val_ids in folder.split(train):\n",
    "            cv_train = train.iloc[cv_train_ids]\n",
    "            cv_val = train.iloc[cv_val_ids]\n",
    "            \n",
    "            cv_quanitles = cv_train.groupby(cols)[target]\\\n",
    "                .quantile(qs)\\\n",
    "                .unstack()\\\n",
    "                .rename({q : qname for q, qname in zip(qs, qnames)}, axis = 1)\n",
    "            \n",
    "            train_enc = train_enc + [cv_val.join(cv_quanitles, on = cols, how = 'left')]\n",
    "        \n",
    "        means = train.groupby(cols)[target]\\\n",
    "            .quantile(qs)\\\n",
    "            .unstack()\\\n",
    "            .rename({q : qname for q, qname in zip(qs, qnames)}, axis = 1)\n",
    "        \n",
    "        return mpd.MapT(lambda df: df.join(means, on = cols, how = 'left')), pd.concat(train_enc)\n",
    "        \n",
    "    return E(fit_qenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizedStuff(cols, target, rsuffix = None, splits = 5):\n",
    "    if rsuffix is None:\n",
    "        rsuffix = ''\n",
    "        \n",
    "    def fit_qenc(train):\n",
    "        folder = KFold(n_splits=splits)\n",
    "        train_enc = []\n",
    "        \n",
    "        for cv_train_ids, cv_val_ids in folder.split(train):\n",
    "            cv_train = train.iloc[cv_train_ids]\n",
    "            cv_val = train.iloc[cv_val_ids]\n",
    "            \n",
    "            cv_means = cv_train.groupby(cols)[target]\\\n",
    "                .agg(['mean', 'std', 'count'])\n",
    "            \n",
    "            cv_means = cv_means.rename({col : '_'.join(cols) + '_' + target + '_' + col + rsuffix for col in cv_means.columns}, axis = 1)\n",
    "            \n",
    "            train_enc = train_enc + [cv_val.join(cv_means, on = cols, how = 'left')]\n",
    "        \n",
    "        means = train.groupby(cols)[target]\\\n",
    "            .agg(['mean', 'std', 'count'])\n",
    "        \n",
    "        means = means.rename({col : '_'.join(cols) + '_' + target + '_' + col + rsuffix for col in means.columns}, axis = 1)\n",
    "        return mpd.MapT(lambda df: df.join(means, on = cols, how = 'left')), pd.concat(train_enc)\n",
    "        \n",
    "    return E(fit_qenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train-parking.csv', parse_dates=['Date']).sort_values('Date')\n",
    "test = pd.read_csv('../data/test-no-labels-with-id.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_info = pd.read_csv('../intersection_locations2.csv').set_index(['Street1', 'Street2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size = 0.3, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_removal = mpd.trainOnly(lambda df: df[(df['Real.Spots'] < 30) & (df['Street'] != 'Redwood Street')])\n",
    "de = dateDecoder('Date')\n",
    "te = timeDecoder('Time')\n",
    "rs1 = regularizedStuff(['Street'], 'Real.Spots')\n",
    "#rs12 = regularizedStuff(['Street', 'From', 'To'], 'any_spot')\n",
    "#rs2 = regularizedStuff(['hour'], 'Real.Spots')\n",
    "qe = regularizedQuanitleEncoding(['Street'], 'Real.Spots', [0,0.25,0.5,0.75,1])\n",
    "qe2 = regularizedQuanitleEncoding(['hour'], 'Real.Spots', [0,0.25,0.5,0.75,1])\n",
    "le = mpd.labelEncoder(['Street', 'From', 'To'])\n",
    "add_latlng = mpd.MapE(lambda df: df.join(intersection_info, on = ['Street', 'From'], how = 'left'))\n",
    "\n",
    "remove = []\n",
    "dropper = mpd.dropCols(['Date', 'Time'] + remove)\n",
    "\n",
    "final_pipe = outlier_removal * pipeline([de, add_latlng, te, qe, qe2, le, dropper, mpd.MapE(lambda df: df.fillna(-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, train2 = final_pipe.fit_transform(train)\n",
    "val2 = t.transform(val)\n",
    "test2 = t.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658838878017\n",
      "0.51724137931\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train2.drop(['Real.Spots', 'any_spot'], axis = 1), \n",
    "                     label = train2['Real.Spots'])\n",
    "dval = xgb.DMatrix(val2.drop(['Real.Spots', 'any_spot'], axis = 1), \n",
    "                   label = val2['Real.Spots'])\n",
    "# specify parameters via map\n",
    "param = {'max_depth':4, 'eta':.01, 'colsample_bytree' : .8, \n",
    "         'subsample' : .8}\n",
    "num_round = 400\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(dval)\n",
    "print(fbeta_score(train2['any_spot'], (bst.predict(dtrain) > 1.1), 0.5))\n",
    "print(fbeta_score(val2['any_spot'], (preds > 1.1), 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street.Length</td>\n",
       "      <td>0.135410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.110340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dow</td>\n",
       "      <td>0.031805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.022405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.020780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Street_encode_75.0%</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hour_encode_100%</td>\n",
       "      <td>0.017636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hour_encode_75.0%</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hour_encode_50.0%</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From</td>\n",
       "      <td>0.002504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Street_encode_25.0%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Street_encode_0%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hour_encode_0%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hour_encode_25.0%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>To</td>\n",
       "      <td>-0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Street_encode_100%</td>\n",
       "      <td>-0.004986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Street_encode_50.0%</td>\n",
       "      <td>-0.009901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    col       imp\n",
       "0         Street.Length  0.135410\n",
       "4             longitude  0.110340\n",
       "3              latitude  0.055556\n",
       "1                   dow  0.031805\n",
       "5                  hour  0.022405\n",
       "16               Street  0.020780\n",
       "9   Street_encode_75.0%  0.019231\n",
       "15     hour_encode_100%  0.017636\n",
       "14    hour_encode_75.0%  0.014493\n",
       "13    hour_encode_50.0%  0.009709\n",
       "17                 From  0.002504\n",
       "7   Street_encode_25.0%  0.000000\n",
       "6      Street_encode_0%  0.000000\n",
       "11       hour_encode_0%  0.000000\n",
       "12    hour_encode_25.0%  0.000000\n",
       "2                 month  0.000000\n",
       "18                   To -0.001386\n",
       "10   Street_encode_100% -0.004986\n",
       "8   Street_encode_50.0% -0.009901"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = val2\n",
    "base_score = fbeta_score(df['any_spot'], (bst.predict(xgb.DMatrix(df.drop(['Real.Spots', 'any_spot'], axis = 1))) > 0.5), 0.5)\n",
    "importances = []\n",
    "msk = np.random.permutation(df.shape[0])\n",
    "for col in val2.drop(['Real.Spots', 'any_spot'], axis = 1).columns:\n",
    "    x = df.assign(**{col : df[col].iloc[msk].values})\n",
    "    dx = xgb.DMatrix(x.drop(['Real.Spots', 'any_spot'], axis = 1), \n",
    "                         label = x['any_spot'])\n",
    "    \n",
    "    score = fbeta_score(x['any_spot'], bst.predict(dx) > 0.5, 0.5)\n",
    "    importances.append((col, (base_score - score) /base_score))\n",
    "    \n",
    "res = pd.DataFrame(importances, columns=['col', 'imp']).sort_values('imp', ascending =False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d', 'Street_encode_100%', 'hour_encode_75.0%',\n",
       "       'Street_Real.Spots_count', 'Street_Real.Spots_std',\n",
       "       'hour_Real.Spots_mean', 'hour_Real.Spots_count', 'dow',\n",
       "       'hour_Real.Spots_std', 'latitude', 'To', 'Street_Real.Spots_mean',\n",
       "       'From'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res['imp'] < 0]['col'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = bst.predict(xgb.DMatrix(test2.drop('id', axis = 1))) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'any_spot' : test_preds}, index = test2['id']).to_csv('../predictions/xgboost_new_pipeline_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
